ABOUT
vedere about pagina statica
ADDADMIN
vedere addAdmin pagina statica
ADMINTOOLS
vedere adminTools pagina statica
ARTICLE
vedere article parte statica
ARTICLE_LINKS
vedere article_links parte statica
CREATE_ARGUMENTS
vedere Create_arguments parte statica
INDEX
vedere imdex parte statica
LOGIN
vedi parte statica
MANAGE_USERS
vedi parte statica
PROFILE
vedi parte statica
REGISTRATION 
vedi parte statica
RESEARCH_RESULT
vedi parte statica
WRITE_ARTICLE
vedi parte statica

Algorithms

(Descrizione)In mathematics and computer science, an algorithm is an unambiguous specification of how to solve a class of problems.
Algorithms can perform calculation, data processing, and automated reasoning tasks.
Algorithms are essential to the way computers process data. Many computer programs contain algorithms that detail the specific instructions a computer should perform (in a specific order) to carry out a specified task, such as calculating employees' paychecks or printing students' report cards.
Thus, an algorithm can be considered to be any sequence of operations that can be simulated by a Turing-complete system.
Typically, when an algorithm is associated with processing information, data can be read from an input source, written to an output device and stored for further processing.
Stored data are regarded as part of the internal state of the entity performing the algorithm.
In practice, the state is stored in one or more data structures.
For some such computational process, the algorithm must be rigorously defined: specified in the way it applies in all possible circumstances that could arise.
That is, any conditional steps must be systematically dealt with, case-by-case; the criteria for each case must be clear (and computable).
Because an algorithm is a precise list of precise steps, the order of computation is always crucial to the functioning of the algorithm.
Instructions are usually assumed to be listed explicitly, and are described as starting "from the top" and going "down to the bottom", an idea that is described more formally by flow of control.
So far, this discussion of the formalization of an algorithm has assumed the premises of imperative programming. This is the most common conception, and it attempts to describe a task in discrete, "mechanical" means.
Unique to this conception of formalized algorithms is the assignment operation, setting the value of a variable.
It derives from the intuition of "memory" as a scratchpad. 

    Dynamic Programming

    Dynamic programming is both a mathematical optimization method and a computer programming method.

        Computer programming

            <h3>Introduction</h3>
            <p>There are two key attributes that a problem must have in order for dynamic programming to be applicable: optimal substructure and overlapping sub-problems.
            If a problem can be solved by combining optimal solutions to non-overlapping sub-problems, the strategy is called "divide and conquer" instead. 
            This is why merge sort and quick sort are not classified as dynamic programming problems.
            </p>
            <p>
            Optimal substructure means that the solution to a given optimization problem can be obtained by the combination of optimal solutions to its sub-problems.
            Such optimal substructures are usually described by means of recursion. For example, given a graph G=(V,E), the shortest path p from a vertex u to a vertex v exhibits optimal substructure: take any intermediate vertex w on this shortest path p.
            If p is truly the shortest path, then it can be split into sub-paths p1 from u to w and p2 from w to v such that these, in turn, are indeed the shortest paths between the corresponding vertices.
            Hence, one can easily formulate the solution for finding shortest paths in a recursive manner, which is what the Bellman–Ford algorithm or the Floyd–Warshall algorithm does.
            Overlapping sub-problems means that the space of sub-problems must be small, that is, any recursive algorithm solving the problem should solve the same sub-problems over and over, rather than generating new sub-problems.
            For example, consider the recursive formulation for generating the Fibonacci series: Fi = Fi−1 + Fi−2, with base case F1 = F2 = 1. Then F43 = F42 + F41, and F42 = F41 + F40.
            Now F41 is being solved in the recursive sub-trees of both F43 as well as F42. Even though the total number of sub-problems is actually small (only 43 of them), we end up solving the same problems over and over if we adopt a naive recursive solution such as this.
            Dynamic programming takes account of this fact and solves each sub-problem only once.
            </p>
            <h3>This can be achieved in either of two ways:</h3>
            <h4>Top-down approach</h4>
            <p>
            This is the direct fall-out of the recursive formulation of any problem. 
            If the solution to any problem can be formulated recursively using the solution to its sub-problems, and if its sub-problems are overlapping, then one can easily memoize or store the solutions to the sub-problems in a table.
            Whenever we attempt to solve a new sub-problem, we first check the table to see if it is already solved. 
            If a solution has been recorded, we can use it directly, otherwise we solve the sub-problem and add its solution to the table.
            </p>
            <h4>Bottom-up approach</h4>
            <p>
            Once we formulate the solution to a problem recursively as in terms of its sub-problems, we can try reformulating the problem in a bottom-up fashion: try solving the sub-problems first and use their solutions to build-on and arrive at solutions to bigger sub-problems.
            This is also usually done in a tabular form by iteratively generating solutions to bigger and bigger sub-problems by using the solutions to small sub-problems.
            For example, if we already know the values of F41 and F40, we can directly calculate the value of F42.
            Some programming languages can automatically memoize the result of a function call with a particular set of arguments, in order to speed up call-by-name evaluation (this mechanism is referred to as call-by-need).
            Some languages make it possible portably (e.g. Scheme, Common Lisp or Perl).
            Some languages have automatic memoization built in, such as tabled Prolog and J, which supports memoization with the M. adverb.
            In any case, this is only possible for a referentially transparent function.
            </p>

        Fibonacci sequence
            
            <h3>Introduction</h3>
            <p>
            In mathematics, the Fibonacci numbers, commonly denoted Fn form a sequence, called the Fibonacci sequence, such that each number is the sum of the two preceding ones, starting from 0 and 1. 
            </p>
            <p>
            That is, F 0 = 0 , F 1 = 1 ,
            and
            F n = F n − 1 + F n − 2 ,
            for n > 1.
            </p>
            <p>
            One has F2 = 1. In some books, and particularly in old ones, F0, the "0" is omitted, and the Fibonacci sequence starts with F1 = F2 = 1.
            The beginning of the sequence is thus:
            ( 0 , ) 1 , 1 , 2 , 3 , 5 , 8 , 13 , 21 , 34 , 55 , 89 , 144 , … 
            Fibonacci numbers are strongly related to the golden ratio: Binet's formula expresses the nth Fibonacci number in terms of n and the golden ratio, and implies that the ratio of two consecutive Fibonacci numbers tends to the golden ratio as n increases.
            Fibonacci numbers are named after Italian mathematician Leonardo of Pisa, later known as Fibonacci.
            They appear to have first arisen as early as 200 BC in work by Pingala on enumerating possible patterns of poetry formed from syllables of two lengths.
            In his 1202 book Liber Abaci, Fibonacci introduced the sequence to Western European mathematics, although the sequence had been described earlier in Indian mathematics.
            Fibonacci numbers appear unexpectedly often in mathematics, so much so that there is an entire journal dedicated to their study, the Fibonacci Quarterly. 
            Applications of Fibonacci numbers include computer algorithms such as the Fibonacci search technique and the Fibonacci heap data structure, and graphs called Fibonacci cubes used for interconnecting parallel and distributed systems.
            They also appear in biological settings, such as branching in trees, the arrangement of leaves on a stem, the fruit sprouts of a pineapple, the flowering of an artichoke, an uncurling fern and the arrangement of a pine cone's bracts.
            Fibonacci numbers are also closely related to Lucas numbers L_{n} in that they form a complementary pair of Lucas sequences U n ( 1 , − 1 ) = F n and V n ( 1 , − 1 ) = L n .
            Lucas numbers are also intimately connected with the golden ratio.
            </p>
            <h3>Mathematics</h3>
            <p>
            The Fibonacci numbers occur in the sums of "shallow" diagonals in Pascal's triangle (see binomial coefficient):
            F n = ∑ k = 0 ⌊ n − 1 2 ⌋ ( n − k − 1 k ).
            These numbers also give the solution to certain enumerative problems. The most common is that of counting the number of compositions of 1s and 2s which sum to a given total n: there are Fn+1 ways to do this.
            For example, if n = 5, then Fn+1 = F6 = 8 counts the eight compositions summing to 5:
            1+1+1+1+1 = 1+1+1+2 = 1+1+2+1 = 1+2+1+1 = 2+1+1+1 = 2+2+1 = 2+1+2 = 1+2+2.
            The Fibonacci numbers can be found in different ways among the set of binary strings, or equivalently, among the subsets of a given set.
            The number of binary strings of length n without consecutive 1s is the Fibonacci number Fn+2. For example, out of the 16 binary strings of length 4, there are F6 = 8 without consecutive 1s – they are 0000, 0001, 0010, 0100, 0101, 1000, 1001 and 1010. By symmetry, the number of strings of length n without consecutive 0s is also Fn+2. Equivalently, Fn+2 is the number of subsets S ⊂ {1,...,n} without consecutive integers: {i, i+1} ⊄ S for every i. The symmetric statement is: Fn+2 is the number of subsets S ⊂ {1,...,n} without two consecutive skipped integers: that is, S = {a1 < ... < ak} with ai+1 ≤ ai + 2.
            The number of binary strings of length n without an odd number of consecutive 1s is the Fibonacci number Fn+1. For example, out of the 16 binary strings of length 4, there are F5 = 5 without an odd number of consecutive 1s – they are 0000, 0011, 0110, 1100, 1111. Equivalently, the number of subsets S ⊂ {1,...,n} without an odd number of consecutive integers is Fn+1.
            The number of binary strings of length n without an even number of consecutive 0s or 1s is 2Fn. For example, out of the 16 binary strings of length 4, there are 2F4 = 6 without an even number of consecutive 0s or 1s – they are 0001, 0111, 0101, 1000, 1010, 1110. There is an equivalent statement about subsets.
            </p>
            <h4>Sequence properties</h4>
            <p>
            The first 21 Fibonacci numbers Fn for n = 0, 1, 2, ..., 20 are:
            F0 	F1 	F2 	F3 	F4 	F5 	F6 	F7 	F8 	F9 	F10 	F11 	F12 	F13 	F14 	F15 	F16 	F17 	F18 	F19 	F20
            0 	1 	1 	2 	3 	5 	8 	13 	21 	34 	55 	89 	144 	233 	377 	610 	987 	1597 	2584 	4181 	6765 
            The sequence can also be extended to negative index n using the re-arranged recurrence relation
            F n − 2 = F n − F n − 1 , 
            which yields the sequence of "negafibonacci" numbers satisfying
            F − n = ( − 1 ) n + 1 F n .
            Thus the bidirectional sequence is
            F−8 	F−7 	F−6 	F−5 	F−4 	F−3 	F−2 	F−1 	F0 	F1 	F2 	F3 	F4 	F5 	F6 	F7 	F8
            −21 	13 	−8 	5 	−3 	2 	−1 	1 	0 	1 	1 	2 	3 	5 	8 	13 	21
            </p>
            <h4>Relation to the golden ratio</h4>
            <p>
            Like every sequence defined by a linear recurrence with constant coefficients, the Fibonacci numbers have a closed-form solution. It has become known as "Binet's formula", though it was already known by Abraham de Moivre and Daniel Bernoulli:
            F n = φ n − ψ n φ − ψ = φ n − ψ n 5 
            where
            φ = 1 + 5 2 ≈ 1.61803 39887 …
            is the golden ratio (OEIS: A001622), and
            ψ = 1 − 5 2 = 1 − φ = − 1 φ ≈ − 0.61803 39887 … . 
            Since ψ = − φ − 1 , this formula can also be written as
            F n = φ n − ( − φ ) − n 5 = φ n − ( − φ ) − n 2 φ − 1 
            To see this, note that φ and ψ are both solutions of the equations
            x 2 = x + 1 and x n = x n − 1 + x n − 2 ,
            so the powers of φ and ψ satisfy the Fibonacci recursion. In other words,
            φ n = φ n − 1 + φ n − 2 
            and
            ψ n = ψ n − 1 + ψ n − 2 .
            It follows that for any values a and b, the sequence defined by
            U n = a φ n + b ψ n
            satisfies the same recurrence
            U n = a φ n − 1 + b ψ n − 1 + a φ n − 2 + b ψ n − 2 = U n − 1 + U n − 2 .
            If a and b are chosen so that U0 = 0 and U1 = 1 then the resulting sequence Un must be the Fibonacci sequence. This is the same as requiring a and b satisfy the system of equations:
            { a + b = 0 φ a + ψ b = 1
            which has solution
            a = 1 φ − ψ = 1 5 , b = − a ,
            producing the required formula.
            Taking the starting values U0 and U1 to be arbitrary constants, a more general solution is:
            U n = a φ n + b ψ n
            where
            a = U 1 − U 0 ψ 5
            b = U 0 φ − U 1 5 .
            </p>


        Dijkstra's algorithm

            <h3>Introduction</h3>
            <p>
            Dijkstra's algorithm is an algorithm for finding the shortest paths between nodes in a graph, which may represent, for example, road networks. 
            It was conceived by computer scientist Edsger W. Dijkstra in 1956 and published three years later.
            The algorithm exists in many variants; Dijkstra's original variant found the shortest path between two nodes, but a more common variant fixes a single node as the "source" node and finds shortest paths from the source to all other nodes in the graph, producing a shortest-path tree.
            For a given source node in the graph, the algorithm finds the shortest path between that node and every other.
            It can also be used for finding the shortest paths from a single node to a single destination node by stopping the algorithm once the shortest path to the destination node has been determined.
            For example, if the nodes of the graph represent cities and edge path costs represent driving distances between pairs of cities connected by a direct road, Dijkstra's algorithm can be used to find the shortest route between one city and all other cities. 
            As a result, the shortest path algorithm is widely used in network routing protocols, most notably IS-IS (Intermediate System to Intermediate System) and Open Shortest Path First (OSPF). 
            It is also employed as a subroutine in other algorithms such as Johnson's.
            </p>
            <p>
            The Dijkstra algorithm uses labels that are positive integer or real numbers, which have the strict weak ordering defined.
            Interestingly, Dijkstra can be generalized to use labels defined in any way, provided they have the strict partial order defined, and provided the subsequent labels (a subsequent label is produced when traversing an edge) are monotonically non-decreasing. 
            This generalization is called the Generic Dijkstra shortest-path algorithm.
            Dijkstra's original algorithm does not use a min-priority queue and runs in time O ( | V | 2 ).
            The idea of this algorithm is also given in Leyzorek et al. 1957. The implementation based on a min-priority queue implemented by a Fibonacci heap and running in O ( | E | + | V | log ⁡ | V | )
            In some fields, artificial intelligence in particular, Dijkstra's algorithm or a variant of it is known as uniform cost search and formulated as an instance of the more general idea of best-first search.
            </p>
            
            <h3>Algorithm</h3>
            <ul>
            <li>Let the node at which we are starting be called the initial node.</li>
            <li>Let the distance of node Y be the distance from the initial node to Y.</li>
            </ul>
            <p>
            Dijkstra's algorithm will assign some initial distance values and will try to improve them step by step.
            </p>
            <ol>
            <li>Mark all nodes unvisited. Create a set of all the unvisited nodes called the unvisited set.</li>
            <li>Assign to every node a tentative distance value: set it to zero for our initial node and to infinity for all other nodes. Set the initial node as current.</li>
            <li>For the current node, consider all of its unvisited neighbors and calculate their tentative distances through the current node. Compare the newly calculated tentative distance to the current assigned value and assign the smaller one. For example, if the current node A is marked with a distance of 6, and the edge connecting it with a neighbor B has length 2, then the distance to B through A will be 6 + 2 = 8. If B was previously marked with a distance greater than 8 then change it to 8. Otherwise, keep the current value.</li>
            <li>When we are done considering all of the unvisited neighbors of the current node, mark the current node as visited and remove it from the unvisited set. A visited node will never be checked again.</li>
            <li>If the destination node has been marked visited (when planning a route between two specific nodes) or if the smallest tentative distance among the nodes in the unvisited set is infinity (when planning a complete traversal; occurs when there is no connection between the initial node and remaining unvisited nodes), then stop. The algorithm has finished.</li>
            <li>Otherwise, select the unvisited node that is marked with the smallest tentative distance, set it as the new "current node", and go back to step 3.</li>
            </ol>
            <p>
            When planning a route, it is actually not necessary to wait until the destination node is "visited" as above: the algorithm can stop once the destination node has the smallest tentative distance among all "unvisited" nodes (and thus could be selected as the next "current").
            </p>
            <h3>Description</h3>
            <p>
            Suppose you would like to find the shortest path between two intersections on a city map: a starting point and a destination. Dijkstra's algorithm initially marks the distance (from the starting point) to every other intersection on the map with infinity. This is done not to imply there is an infinite distance, but to note that those intersections have not yet been visited; some variants of this method simply leave the intersections' distances unlabeled. Now, at each iteration, select the current intersection. For the first iteration, the current intersection will be the starting point, and the distance to it (the intersection's label) will be zero. For subsequent iterations (after the first), the current intersection will be a closest unvisited intersection to the starting point (this will be easy to find).
            From the current intersection, update the distance to every unvisited intersection that is directly connected to it. This is done by determining the sum of the distance between an unvisited intersection and the value of the current intersection, and relabeling the unvisited intersection with this value (the sum), if it is less than its current value. In effect, the intersection is relabeled if the path to it through the current intersection is shorter than the previously known paths. To facilitate shortest path identification, in pencil, mark the road with an arrow pointing to the relabeled intersection if you label/relabel it, and erase all others pointing to it. After you have updated the distances to each neighboring intersection, mark the current intersection as visited, and select an unvisited intersection with minimal distance (from the starting point) – or the lowest label—as the current intersection. Intersections marked as visited are labeled with the shortest path from the starting point to it and will not be revisited or returned to.
            Continue this process of updating the neighboring intersections with the shortest distances, then marking the current intersection as visited and moving onto a closest unvisited intersection until you have marked the destination as visited. Once you have marked the destination as visited (as is the case with any visited intersection) you have determined the shortest path to it, from the starting point, and can trace your way back, following the arrows in reverse; in the algorithm's implementations, this is usually done (after the algorithm has reached the destination node) by following the nodes' parents from the destination node up to the starting node; that's why we also keep track of each node's parent.
            This algorithm makes no attempt of direct "exploration" towards the destination as one might expect. Rather, the sole consideration in determining the next "current" intersection is its distance from the starting point. This algorithm therefore expands outward from the starting point, interactively considering every node that is closer in terms of shortest path distance until it reaches the destination. When understood in this way, it is clear how the algorithm necessarily finds the shortest path. However, it may also reveal one of the algorithm's weaknesses: its relative slowness in some topologies. 
            </p>
    
    Binary Search tree
        
    In computer science, binary search trees (BST), sometimes called ordered or sorted binary trees, are a particular type of container: data structures that store "items" (such as numbers, names etc.) in memory.

        Red-Black trees

            <h3>Introduction</h3>
            <p>
            A red–black tree is a kind of self-balancing binary search tree in computer science. 
            Each node of the binary tree has an extra bit, and that bit is often interpreted as the color (red or black) of the node. 
            These color bits are used to ensure the tree remains approximately balanced during insertions and deletions.
            Balance is preserved by painting each node of the tree with one of two colors in a way that satisfies certain properties, which collectively constrain how unbalanced the tree can become in the worst case.
            When the tree is modified, the new tree is subsequently rearranged and repainted to restore the coloring properties.
            The properties are designed in such a way that this rearranging and recoloring can be performed efficiently.
            </p>
            <p>
            The balancing of the tree is not perfect, but it is good enough to allow it to guarantee searching in O(log n) time, where n is the total number of elements in the tree. 
            The insertion and deletion operations, along with the tree rearrangement and recoloring, are also performed in O(log n) time.
            Tracking the color of each node requires only 1 bit of information per node because there are only two colors.
            The tree does not contain any other data specific to its being a red–black tree so its memory footprint is almost identical to a classic (uncolored) binary search tree. 
            In many cases, the additional bit of information can be stored at no additional memory cost. 
            </p>

            <h3>Terminology</h3>
            <p>
            A red–black tree is a special type of binary tree, used in computer science to organize pieces of comparable data, such as text fragments or numbers.
            The leaf nodes of red–black trees do not contain data. These leaves need not be explicit in computer memory—a null child pointer can encode the fact that this child is a leaf—but it simplifies some algorithms for operating on red–black trees if the leaves really are explicit nodes. To save execution time, sometimes a pointer to a single sentinel node (instead of a null pointer) performs the role of all leaf nodes; all references from internal nodes to leaf nodes then point to the sentinel node.
            Red–black trees, like all binary search trees, allow efficient in-order traversal (that is: in the order Left–Root–Right) of their elements.
            The search-time results from the traversal from root to leaf, and therefore a balanced tree of n nodes, having the least possible tree height, results in O(log n) search time.
            </p>
            <h3>Properties</h3>
            <ul>In addition to the requirements imposed on a binary search tree the following must be satisfied by a red–black tree:
            
            <li>Each node is either red or black.</li>
            <li>The root is black. This rule is sometimes omitted. Since the root can always be changed from red to black, but not necessarily vice versa, this rule has little effect on analysis.</li>
            <li>All leaves (NIL) are black.</li>
            <li>If a node is red, then both its children are black.</li>
            <li>Every path from a given node to any of its descendant NIL nodes contains the same number of black nodes.</li>
            </ul>
            <p>
            Some definitions: the number of black nodes from the root to a node is the node's black depth; the uniform number of black nodes in all paths from root to the leaves is called the black-height of the red–black tree.
            These constraints enforce a critical property of red–black trees: the path from the root to the farthest leaf is no more than twice as long as the path from the root to the nearest leaf. The result is that the tree is roughly height-balanced. Since operations such as inserting, deleting, and finding values require worst-case time proportional to the height of the tree, this theoretical upper bound on the height allows red–black trees to be efficient in the worst case, unlike ordinary binary search trees.
            To see why this is guaranteed, it suffices to consider the effect of properties 4 and 5 together. For a red–black tree T, let B be the number of black nodes in property 5. Let the shortest possible path from the root of T to any leaf consist of B black nodes. Longer possible paths may be constructed by inserting red nodes. However, property 4 makes it impossible to insert more than one consecutive red node. Therefore, ignoring any black NIL leaves, the longest possible path consists of 2*B nodes, alternating black and red (this is the worst case). Counting the black NIL leaves, the longest possible path consists of 2*B-1 nodes.
            The shortest possible path has all black nodes, and the longest possible path alternates between red and black nodes. Since all maximal paths have the same number of black nodes, by property 5, this shows that no path is more than twice as long as any other path. 
            </p>

Operating System

(Descrizione)An operating system (OS) is system software that manages computer hardware and software resources and provides common services for computer programs.
Time-sharing operating systems schedule tasks for efficient use of the system and may also include accounting software for cost allocation of processor time, mass storage, printing, and other resources.
For hardware functions such as input and output and memory allocation, the operating system acts as an intermediary between programs and the computer hardware, although the application code is usually executed directly by the hardware and frequently makes system calls to an OS function or is interrupted by it.
Operating systems are found on many devices that contain a computer – from cellular phones and video game consoles to web servers and supercomputers.
The dominant desktop operating system is Microsoft Windows with a market share of around 82.74%. macOS by Apple Inc. is in second place (13.23%), and the varieties of Linux are collectively in third place (1.57%).
In the mobile (smartphone and tablet combined) sector, use in 2017 is up to 70% of Google's Android and according to third quarter 2016 data, Android on smartphones is dominant with 87.5 percent and a growth rate 10.3 percent per year, followed by Apple's iOS with 12.1 percent and a per year decrease in market share of 5.2 percent, while other operating systems amount to just 0.3 percent.
Linux distributions are dominant in the server and supercomputing sectors. Other specialized classes of operating systems, such as embedded and real-time systems, exist for many applications.

    Kernel

    With the aid of the firmware and device drivers, the kernel provides the most basic level of control over all of the computer's hardware devices.
    It manages memory access for programs in the RAM, it determines which programs get access to which hardware resources, it sets up or resets the CPU's operating states for optimal operation at all times, and it organizes the data for long-term non-volatile storage with file systems on such media as disks, tapes, flash memory, etc.

        Process computing
        
            <h3>Introduction</h3>
            <p>
            In computing, a process is the instance of a computer program that is being executed. It contains the program code and its activity. Depending on the operating system (OS), a process may be made up of multiple threads of execution that execute instructions concurrently.
            While a computer program is a passive collection of instructions, a process is the actual execution of those instructions. Several processes may be associated with the same program; for example, opening up several instances of the same program often results in more than one process being executed.
            Multitasking is a method to allow multiple processes to share processors (CPUs) and other system resources. Each CPU (core) executes a single task at a time. However, multitasking allows each processor to switch between tasks that are being executed without having to wait for each task to finish. Depending on the operating system implementation, switches could be performed when tasks perform input/output operations, when a task indicates that it can be switched, or on hardware interrupts.
            A common form of multitasking is time-sharing. Time-sharing is a method to allow high responsiveness for interactive user applications. In time-sharing systems, context switches are performed rapidly, which makes it seem like multiple processes are being executed simultaneously on the same processor. This seeming execution of multiple processes simultaneously is called concurrency.
            For security and reliability, most modern operating systems prevent direct communication between independent processes, providing strictly mediated and controlled inter-process communication functionality.
            </p>
            <h3>Representation</h3>
            <p>
            In general, a computer system process consists of (or is said to own) the following resources:
            An image of the executable machine code associated with a program.
            Memory (typically some region of virtual memory); which includes the executable code, process-specific data (input and output), a call stack (to keep track of active subroutines and/or other events), and a heap to hold intermediate computation data generated during run time.
            Operating system descriptors of resources that are allocated to the process, such as file descriptors (Unix terminology) or handles (Windows), and data sources and sinks.
            Security attributes, such as the process owner and the process' set of permissions (allowable operations).
            Processor state (context), such as the content of registers and physical memory addressing. The state is typically stored in computer registers when the process is executing, and in memory otherwise.
            The operating system holds most of this information about active processes in data structures called process control blocks. Any subset of the resources, typically at least the processor state, may be associated with each of the process' threads in operating systems that support threads or child (daughter) processes.
            The operating system keeps its processes separate and allocates the resources they need, so that they are less likely to interfere with each other and cause system failures (e.g., deadlock or thrashing). The operating system may also provide mechanisms for inter-process communication to enable processes to interact in safe and predictable ways
            </p>
            <h3>Multitasking and process management</h3>
            <p>
            A multitasking operating system may just switch between processes to give the appearance of many processes executing simultaneously (that is, in parallel), though in fact only one process can be executing at any one time on a single CPU (unless the CPU has multiple cores, then multithreading or other similar technologies can be used).
            It is usual to associate a single process with a main program, and child processes with any spin-off, parallel processes, which behave like asynchronous subroutines. A process is said to own resources, of which an image of its program (in memory) is one such resource. However, in multiprocessing systems many processes may run off of, or share, the same reentrant program at the same location in memory, but each process is said to own its own image of the program.
            Processes are often called "tasks" in embedded operating systems. The sense of "process" (or task) is "something that takes up time", as opposed to "memory", which is "something that takes up space".
            The above description applies to both processes managed by an operating system, and processes as defined by process calculi.
            If a process requests something for which it must wait, it will be blocked. When the process is in the blocked state, it is eligible for swapping to disk, but this is transparent in a virtual memory system, where regions of a process's memory may be really on disk and not in main memory at any time. Note that even unused portions of active processes/tasks (executing programs) are eligible for swapping to disk. All parts of an executing program and its data do not have to be in physical memory for the associated process to be active.
            </p>
            <h4>Process states</h4>
            <p>
            An operating system kernel that allows multitasking needs processes to have certain states. Names for these states are not standardised, but they have similar functionality.
            First, the process is "created" by being loaded from a secondary storage device (hard disk drive, CD-ROM, etc.) into main memory. After that the process scheduler assigns it the "waiting" state.
            While the process is "waiting", it waits for the scheduler to do a so-called context switch and load the process into the processor. The process state then becomes "running", and the processor executes the process instructions.
            If a process needs to wait for a resource (wait for user input or file to open, for example), it is assigned the "blocked" state. The process state is changed back to "waiting" when the process no longer needs to wait (in a blocked state).
            Once the process finishes execution, or is terminated by the operating system, it is no longer needed. The process is removed instantly or is moved to the "terminated" state. When removed, it just waits to be removed from main memory.
            </p>
        
        Interrupts

            <p>
            In system programming, an interrupt is a signal to the processor emitted by hardware or software indicating an event that needs immediate attention. An interrupt alerts the processor to a high-priority condition requiring the interruption of the current code the processor is executing. The processor responds by suspending its current activities, saving its state, and executing a function called an interrupt handler (or an interrupt service routine, ISR) to deal with the event. This interruption is temporary, and, after the interrupt handler finishes, the processor resumes normal activities. There are two types of interrupts: hardware interrupts and software interrupts.
            </p>
            <p>
            Hardware interrupts are used by devices to communicate that they require attention from the operating system. Internally, hardware interrupts are implemented using electronic alerting signals that are sent to the processor from an external device, which is either a part of the computer itself, such as a disk controller, or an external peripheral. For example, pressing a key on the keyboard or moving the mouse triggers hardware interrupts that cause the processor to read the keystroke or mouse position. Unlike the software type (described below), hardware interrupts are asynchronous and can occur in the middle of instruction execution, requiring additional care in programming. The act of initiating a hardware interrupt is referred to as an interrupt request (IRQ).
            </p>
            <p>
            A software interrupt is caused either by an exceptional condition in the processor itself, or a special instruction in the instruction set which causes an interrupt when it is executed. The former is often called a trap or exception and is used for errors or events occurring during program execution that are exceptional enough that they cannot be handled within the program itself. For example, a divide-by-zero exception will be thrown if the processor's arithmetic logic unit is commanded to divide a number by zero as this instruction is an error and impossible. The operating system will catch this exception, and can decide what to do about it: usually aborting the process and displaying an error message. Software interrupt instructions can function similarly to subroutine calls and are used for a variety of purposes, such as to request services from device drivers, like interrupts sent to and from a disk controller to request reading or writing of data to and from the disk.
            </p>
            <p>
            Each interrupt has its own interrupt handler. The number of hardware interrupts is limited by the number of interrupt request (IRQ) lines to the processor, but there may be hundreds of different software interrupts. Interrupts are a commonly used technique for computer multitasking, especially in real-time computing. Such a system is said to be interrupt-driven.
            </p>
            <p>
            Interrupts are similar to signals, the difference being that signals are used for inter-process communication (IPC), mediated by the kernel (possibly via system calls) and handled by processes, while interrupts are mediated by the processor and handled by the kernel. The kernel may pass an interrupt as a signal to the process that caused it (typical examples are SIGSEGV, SIGBUS, SIGILL and SIGFPE). 
            </p>

        Memory management

            <h3>Introduction</h3>
            <p>
            Memory management is a form of resource management applied to computer memory. The essential requirement of memory management is to provide ways to dynamically allocate portions of memory to programs at their request, and free it for reuse when no longer needed. This is critical to any advanced computer system where more than a single process might be underway at any time.
            </p>
            <p>
            Several methods have been devised that increase the effectiveness of memory management. Virtual memory systems separate the memory addresses used by a process from actual physical addresses, allowing separation of processes and increasing the size of the virtual address space beyond the available amount of RAM using paging or swapping to secondary storage. The quality of the virtual memory manager can have an extensive effect on overall system performance. 
            </p>
            <h4>Dynamic memory allocation</h4>
            <p>
            The task of fulfilling an allocation request consists of locating a block of unused memory of sufficient size. Memory requests are satisfied by allocating portions from a large pool of memory called the heap or free store. At any given time, some parts of the heap are in use, while some are "free" (unused) and thus available for future allocations.
            Several issues complicate the implementation, such as external fragmentation, which arises when there are many small gaps between allocated memory blocks, which invalidates their use for an allocation request. The allocator's metadata can also inflate the size of (individually) small allocations. This is often managed by chunking. The memory management system must track outstanding allocations to ensure that they do not overlap and that no memory is ever "lost" (i.e. that there be no "memory leak").
            </p>
            <h4>Efficiency</h4>
            <p>
            The specific dynamic memory allocation algorithm implemented can impact performance significantly. A study conducted in 1994 by Digital Equipment Corporation illustrates the overheads involved for a variety of allocators. The lowest average instruction path length required to allocate a single memory slot was 52 (as measured with an instruction level profiler on a variety of software).
            </p>
            <h4>Implementations</h4>
            <p>
            Since the precise location of the allocation is not known in advance, the memory is accessed indirectly, usually through a pointer reference. The specific algorithm used to organize the memory area and allocate and deallocate chunks is interlinked with the kernel, and may use any of the following methods:
            </p>
            <h4>Fixed-size blocks allocation</h4>
            <p>
            Fixed-size blocks allocation, also called memory pool allocation, uses a free list of fixed-size blocks of memory (often all of the same size). This works well for simple embedded systems where no large objects need to be allocated, but suffers from fragmentation, especially with long memory addresses. However, due to the significantly reduced overhead this method can substantially improve performance for objects that need frequent allocation / de-allocation and is often used in video games.
            </p>
            <h4>Buddy blocks</h4>
            <p>
            In this system, memory is allocated into several pools of memory instead of just one, where each pool represents blocks of memory of a certain power of two in size, or blocks of some other convenient size progression. All blocks of a particular size are kept in a sorted linked list or tree and all new blocks that are formed during allocation are added to their respective memory pools for later use. If a smaller size is requested than is available, the smallest available size is selected and split. One of the resulting parts is selected, and the process repeats until the request is complete. When a block is allocated, the allocator will start with the smallest sufficiently large block to avoid needlessly breaking blocks. When a block is freed, it is compared to its buddy. If they are both free, they are combined and placed in the correspondingly larger-sized buddy-block list.
            </p>
            <h4>Slab allocation</h4>
            <p>
            This memory allocation mechanism preallocates memory chunks suitable to fit objects of a certain type or size. These chunks are called caches and the allocator only has to keep track of a list of free cache slots. Constructing an object will use any one of the free cache slots and destructing an object will add a slot back to the free cache slot list. This technique alleviates memory fragmentation and is efficient as there is no need to search for a suitable portion of memory, as any open slot will suffice.
            </p>
            <h4>Automatic variables</h4>
            <p>
            In many programming language implementations, all variables declared within a procedure (subroutine, or function) are local to that function; the runtime environment for the program automatically allocates memory for these variables on program execution entry to the procedure, and automatically releases that memory when the procedure is exited. Special declarations may allow local variables to retain values between invocations of the procedure, or may allow local variables to be accessed by other procedures. The automatic allocation of local variables makes recursion possible, to a depth limited by available memory.
            </p>
            <h4>Garbage collection</h4>
            <p>
            Garbage collection is a strategy for automatically detecting memory allocated to objects that are no longer usable in a program, and returning that allocated memory to a pool of free memory locations. This method is in contrast to "manual" memory management where a programmer explicitly codes memory requests and memory releases in the program. While automatic garbage has the advantages of reducing programmer workload and preventing certain kinds of memory allocation bugs, garbage collection does require memory resources of its own, and can compete with the application program for processor time.
            </p>

Computer Organization and Architecture

(Descrizione)Computer Organization and Architecture is the study of internal working, structuring and implementation of a computer system.
Architecture in computer system, same as anywhere else, refers to the externally visual attributes of the system.
Externally visual attributes, here in computer science, mean the way a system is visible to the logic of programs (not the human eyes!).
Organization of computer system is the way of practical implementation which results in realization of architectural specifications of a computer system.
In more general language, Architecture of computer system can be considered as a catalog of tools available for any operator using the system, while Organization will be the way the system is structured so that all those cataloged tools can be used, and that in an efficient fashion.

    Von Neaumann architecture

    A major break through came with the draft of second electronic computer, EDVAC.
    This computer was proposed by John von Neumann and others in 1945.
    It used stored program model for computers, wherein all instructions were also to be stored in memory along being data to be processed thereby removing the need for change in hardware structure to change the program.

Automata theory and functionals languages

(Descrizione)Automata theory is the study of abstract machines and automata, as well as the computational problems that can be solved using them. It is a theory in theoretical computer science and discrete mathematics (a subject of study in both mathematics and computer science). The word automata (the plural of automaton) comes from the Greek word αὐτόματα, which means "self-acting".
This automaton consists of states and transitions (represented by arrows). As the automaton sees a symbol of input, it makes a transition (or jump) to another state, according to its transition function, which takes the current state and the recent symbol as its inputs.
Automata theory is closely related to formal language theory. An automaton is a finite representation of a formal language that may be an infinite set. Automata are often classified by the class of formal languages they can recognize, typically illustrated by the Chomsky hierarchy, which describes the relations between various languages and kinds of formalized logic.
Automata play a major role in theory of computation, compiler construction, artificial intelligence, parsing and formal verification.

    Variant definitions of automata

    Automata are defined to study useful machines under mathematical formalism.
    So, the definition of an automaton is open to variations according to the "real world machine", which we want to model using the automaton.
    People have studied many variations of automata. The most standard variant, which is described above, is called a deterministic finite automaton.   
    The following are some popular variations in the definition of different components of automata

    Class of automata

    Different types of automata divided into classes

        Deterministic pushdown automaton(DPDA)
            
            <h3>Introduction</h3>
            <p>
            In automata theory, a deterministic pushdown automaton (DPDA or DPA) is a variation of the pushdown automaton. The class of deterministic pushdown automata accepts the deterministic context-free languages, a proper subset of context-free languages.
            </p>
            <p>
            Machine transitions are based on the current state and input symbol, and also the current topmost symbol of the stack. Symbols lower in the stack are not visible and have no immediate effect. Machine actions include pushing, popping, or replacing the stack top. A deterministic pushdown automaton has at most one legal transition for the same combination of input symbol, state, and top stack symbol. This is where it differs from the nondeterministic pushdown automaton. 
            </p>
            <h3>Formal definition</h3>
            <ol>A (not necessarily deterministic) PDA M can be defined as a 7-tuple:
            M = ( Q , Σ , Γ , q 0 , Z 0 , A , δ )
            where
                <li>Q , is a finite set of states</li>
                <li>Σ , is a finite set of input symbols</li>
                <li>Γ , is a finite set of stack symbols</li>
                <li>q 0 ∈ Q , is the start state</li>
                <li>Z 0 ∈ Γ , is the starting stack symbol</li>
                <li>A ⊆ Q , where A is the set of accepting states</li>
                <li>δ  (delta), is a transition function, where

                δ : ( Q × ( Σ ∪ { ε } ) × Γ ) ⟶ P ( Q × Γ ∗ ) 
                where * is the Kleene star, meaning that Γ ∗ is "the set of all finite strings (including the empty string ε) of elements of Γ , ε denotes the empty string, and P ( X ) is the power set of a set X.</li>
            </ol>
            <ul>M is deterministic if it satisfies both the following conditions:

                <li>For any q ∈ Q , a ∈ Σ ∪ { ε } , x ∈ Γ , the set δ ( q , a , x ), has at most one element.</li>
                <li>For any q ∈ Q , x ∈ Γ , if δ ( q , ε , x ) ≠ ∅ , then δ ( q , a , x ) = ∅  for every a ∈ Σ .</li>
            </ul>
            <p>
            There are two possible acceptance criteria: acceptance by empty stack and acceptance by final state. The two are not equivalent for the deterministic pushdown automaton (although they are for the non-deterministic pushdown automaton). The languages accepted by empty stack are those languages that are accepted by final state and are prefix-free: no word in the language is the prefix of another word in the language.
            The usual acceptance criterion is final state, and it is this acceptance criterion which is used to define the deterministic context-free languages.
            </p>

        Pushdown automaton(PDA)

            <h3>Introduction</h3>
            <p>
            In the theory of computation, a branch of theoretical computer science, a pushdown automaton (PDA) is a type of automaton that employs a stack.
            Pushdown automata are used in theories about what can be computed by machines. They are more capable than finite-state machines but less capable than Turing machines. Deterministic pushdown automata can recognize all deterministic context-free languages while nondeterministic ones can recognize all context-free languages, with the former often used in parser design.
            The term "pushdown" refers to the fact that the stack can be regarded as being "pushed down" like a tray dispenser at a cafeteria, since the operations never work on elements other than the top element. A stack automaton, by contrast, does allow access to and operations on deeper elements. Stack automata can recognize a strictly larger set of languages than pushdown automata. A nested stack automaton allows full access, and also allows stacked values to be entire sub-stacks rather than just single finite symbols. 
            </p>
            <h3>Formal definition</h3>
            <ol>We use standard formal language notation: Γ ∗ denotes the set of strings over alphabet Γ  and ε denotes the empty string.
            A PDA is formally defined as a 7-tuple:
            M = ( Q , Σ , Γ , δ , q 0 , Z , F ) where
            <li>Q is a finite set of states</li>
            <li>Σ is a finite set which is called the input alphabet</li>
            <li>Γ is a finite set which is called the stack alphabet</li>
            <li>δ is a finite subset of Q × ( Σ ∪ { ε } ) × Γ × Q × Γ ∗, the transition relation</li>
            <li>q 0 ∈ Q is the start state</li>
            <li>Z ∈ Γ is the initial stack symbol</li>
            <li>F ⊆ Q is the set of accepting states</li>
            </ol>
            <p>
            An element ( p , a , A , q , α ) ∈ δ is a transition of M. It has the intended meaning that M, in state p ∈ Q, on the input a ∈ Σ ∪ { ε } and with A ∈ Γ as topmost stack symbol, may read a, change the state to q , pop A, replacing it by pushing α ∈ Γ ∗. The ( Σ ∪ { ε } ) component of the transition relation is used to formalize that the PDA can either read a letter from the input, or proceed leaving the input untouched.

            δ is the transition function, mapping Q × ( Σ ∪ { ε } ) × Γ into finite subsets of Q × Γ ∗

            Here δ ( p , a , A ) contains all possible actions in state p with A on the stack, while reading a on the input. One writes for example δ ( p , a , A ) = { ( q , B A ) } precisely when ( q , B A ) ∈ { ( q , B A ) } , ( q , B A ) ∈ δ ( p , a , A ) , because ( ( p , a , A ) , { ( q , B A ) } ) ∈ δ. Note that finite in this definition is essential.
            </p>

        Nondeterministic finite automaton(NFA)

            <h3>Introduction</h3>
            <p>
            In automata theory, a finite state machine is called a deterministic finite automaton (DFA), if
            each of its transitions is uniquely determined by its source state and input symbol, and
            reading an input symbol is required for each state transition.
            </p>
            <p>
            A nondeterministic finite automaton (NFA), or nondeterministic finite state machine, does not need to obey these restrictions. In particular, every DFA is also an NFA. Sometimes the term NFA is used in a narrower sense, referring to a NFA that is not a DFA, but not in this article.
            Using the subset construction algorithm, each NFA can be translated to an equivalent DFA, i.e. a DFA recognizing the same formal language. Like DFAs, NFAs only recognize regular languages.
            NFAs were introduced in 1959 by Michael O. Rabin and Dana Scott, who also showed their equivalence to DFAs. NFAs are used in the implementation of regular expressions: Thompson's construction is an algorithm for compiling a regular expression to an NFA that can efficiently perform pattern matching on strings.
            NFAs have been generalized in multiple ways, e.g., nondeterministic finite automaton with ε-moves, finite state transducers, pushdown automata, alternating automata, ω-automata, and probabilistic automata. Besides the DFAs, other known special cases of NFAs are unambiguous finite automata (UFA) and self-verifying finite automata (SVFA). 
            </p>
            <h3>Formal definition</h3>
            <ul>An NFA is represented formally by a 5-tuple, ( Q , Σ , Δ , q 0 , F ), consisting of
            <li>a finite set of states Q.</li>
            <li>a finite set of input symbols Σ.</li>
            <li>a transition function Δ : Q × Σ → P ( Q ).</li>
            <li>an initial (or start) state q 0 ∈ Q.</li>
            <li>a set of states F distinguished as accepting (or final) states F ⊆ Q.</li>
            </ul>
            <p>
            Here, P ( Q ) denotes the power set of Q. Let w = a 1 a 2 . . . a n be a word over the alphabet Σ. The automaton M accepts the word w if a sequence of states, r 0 , r 1 , . . . , r n , exists in Q with the following conditions:
            r 0 = q 0 
            r i + 1 ∈ Δ ( r i , a i + 1 ), for i = 0 , … , n − 1
            r n ∈ F .
            </p>
            <p>
            In words, the first condition says that the machine starts in the start state q 0. The second condition says that given each character of string w, the machine will transition from state to state according to the transition function Δ . The last condition says that the machine accepts w if the last input of w causes the machine to halt in one of the accepting states. In order for w to be accepted by M, it is not required that every state sequence ends in an accepting state, it is sufficient if one does. Otherwise, i.e. if it is impossible at all to get from q 0 to a state from F by following w, it is said that the automaton rejects the string. The set of strings M accepts is the language recognized by M and this language is denoted by L ( M ).
            We can also define L ( M ) in terms of Δ ∗ : Q × Σ ∗ → P ( Q ) such that:
            Δ ∗ ( r , ϵ ) = { r } where ϵ is the empty string, and
            If x ∈ Σ ∗ , a ∈ Σ , and Δ ∗ ( r , x ) = { r 1 , r 2 , . . . , r k } then Δ ∗ ( r , x a ) = Δ ( r 1 , a ) ∪ . . . ∪ Δ ( r k , a ).
            Now L ( M ) = { w | Δ ∗ ( q 0 , w ) ∩ F ≠ ∅ }.
            Note that there is a single initial state, which is not necessary. Sometimes, NFAs are defined with a set of initial states. There is an easy construction that translates a NFA with multiple initial states to a NFA with single initial state, which provides a convenient notation.
            </p>

        Turing machine

            <h3>Introduction</h3>
            <p>
            A Turing machine is a mathematical model of computation that defines an abstract machine, which manipulates symbols on a strip of tape according to a table of rules. Despite the model's simplicity, given any computer algorithm, a Turing machine capable of simulating that algorithm's logic can be constructed.
            The machine operates on an infinite memory tape divided into discrete cells.
            The machine positions its head over a cell and "reads" (scans) the symbol there. 
            Then, as per the symbol and its present place in a finite table of user-specified instructions, the machine writes a symbol 
            (e.g., a digit or a letter from a finite alphabet) in the cell (some models allowing symbol erasure or no writing), then either moves the tape one cell left or right (some models allow no motion, some models move the head), then (as determined by the observed symbol and the machine's place in the table) either proceeds to a subsequent instruction or halts the computation.
            </p>
            <p>
            The Turing machine was invented in 1936 by Alan Turing, who called it an a-machine (automatic machine).
            With this model, Turing was able to answer two questions in the negative: 
            (1) Does a machine exist that can determine whether any arbitrary machine on its tape is "circular" (e.g., freezes, or fails to continue its computational task); similarly, 
            (2) does a machine exist that can determine whether any arbitrary machine on its tape ever prints a given symbol. 
            Thus by providing a mathematical description of a very simple device capable of arbitrary computations, he was able to prove properties of computation in general—and in particular, the uncomputability of the Entscheidungsproblem ("decision problem").
            Thus, Turing machines prove fundamental limitations on the power of mechanical computation. While they can express arbitrary computations, their minimalistic design makes them unsuitable for computation in practice: real-world computers are based on different designs that, unlike Turing machines, use random-access memory.
            Turing completeness is the ability for a system of instructions to simulate a Turing machine. A programming language that is Turing complete is theoretically capable of expressing all tasks accomplishable by computers; nearly all programming languages are Turing complete if the limitations of finite memory are ignored. 
            </p>
            <h3>Formal definition</h3>
            <ol>Following Hopcroft and Ullman (1979, p. 148), a (one-tape) Turing machine can be formally defined as a 7-tuple M = ⟨ Q , Γ , b , Σ , δ , q 0 , F ⟩ 
            where
            <li>Q is a finite, non-empty set of states;</li>
            <li>Γ is a finite, non-empty set of tape alphabet symbols;</li>
            <li>b ∈ Γ is the blank symbol (the only symbol allowed to occur on the tape infinitely often at any step during the computation);</li>
            <li>Σ ⊆ Γ ∖ { b }  is the set of input symbols, that is, the set of symbols allowed to appear in the initial tape contents;</li>
            <li>q 0 ∈ Q is the initial state;</li>
            <li>F ⊆ Q is the set of final states or accepting states. The initial tape contents is said to be accepted by M if it eventually halts in a state from F.</li>
            <li>δ : ( Q ∖ F ) × Γ ↛ Q × Γ × { L , R } is a partial function called the transition function, where L is left shift, R is right shift.</li>
            </ol>
            <p>
            If δ is not defined on the current state and the current tape symbol, then the machine halts;
            Anything that operates according to these specifications is a Turing machine.
            </p>
            <ul>The 7-tuple for the 3-state busy beaver looks like this (see more about this busy beaver at Turing machine examples):
            <li>Q = { A , B , C , HALT };</li>
            <li>Γ = { 0 , 1 };</li>
            <li>b = 0;</li>
            <li>Σ = { 1 };</li>
            <li>q 0 = A;</li>
            <li>F = { HALT };</li>
            <li>δ.</li>
            </ul>

Programming in Java

(Descrizione)
Java is a popular general-purpose programming language and computing platform. It is fast, reliable, and secure. According to Oracle, the company that owns Java, Java runs on 3 billion devices worldwide.
Considering the number of Java developers, devices running Java, and companies adapting it, it's safe to say that Java will be around for many years to come.
This guide will provide everything you need to know about Java programming language before you learn it. More specifically, you will learn about features of Java programming, its applications, reasons to learn it, and how you can learn it the right way.

    Trails Covering the Basics

    The Java Tutorials are practical guides for programmers who want to use the Java programming language to create applications. They include hundreds of complete, working examples, and dozens of lessons. Groups of related lessons are organized into "trails".

        Getting Started

            <p>
            Java technology is both a programming language and a platform.
            </p>
            <h3>The Java Programming Language</h3>
            <ul>The Java programming language is a high-level language that can be characterized by all of the following buzzwords:

                <li>Simple</li>
                <li>Object oriented</li>
                <li>Distributed</li>
                <li>Multithreaded</li>
                <li>Dynamic</li>

                <li>Architecture neutral</li>
                <li>Portable</li>
                <li>High performance</li>
                <li>Robust</li>
                <li>Secure</li>
            </ul>
            <p>
            Each of the preceding buzzwords is explained in The Java Language Environment , a white paper written by James Gosling and Henry McGilton.
            In the Java programming language, all source code is first written in plain text files ending with the .java extension. Those source files are then compiled into .class files by the javac compiler. A .class file does not contain code that is native to your processor; it instead contains bytecodes — the machine language of the Java Virtual Machine1 (Java VM). The java launcher tool then runs your application with an instance of the Java Virtual Machine.
            Because the Java VM is available on many different operating systems, the same .class files are capable of running on Microsoft Windows, the Solaris™ Operating System (Solaris OS), Linux, or Mac OS. Some virtual machines, such as the Java SE HotSpot at a Glance, perform additional steps at runtime to give your application a performance boost. This includes various tasks such as finding performance bottlenecks and recompiling (to native code) frequently used sections of code.
            </p>
            <h3>The Java Platform</h3>
            <p>
            A platform is the hardware or software environment in which a program runs. We've already mentioned some of the most popular platforms like Microsoft Windows, Linux, Solaris OS, and Mac OS. Most platforms can be described as a combination of the operating system and underlying hardware. The Java platform differs from most other platforms in that it's a software-only platform that runs on top of other hardware-based platforms.
            </p>
            <ul>The Java platform has two components:
                <li>The Java Virtual Machine</li>
                <li>The Java Application Programming Interface (API)</li>
            </ul>
            <p>
            You've already been introduced to the Java Virtual Machine; it's the base for the Java platform and is ported onto various hardware-based platforms.
            The API is a large collection of ready-made software components that provide many useful capabilities. It is grouped into libraries of related classes and interfaces; these libraries are known as packages. The next section, What Can Java Technology Do? highlights some of the functionality provided by the API.
            The API and Java Virtual Machine insulate the program from the underlying hardware.
            As a platform-independent environment, the Java platform can be a bit slower than native code. However, advances in compiler and virtual machine technologies are bringing performance close to that of native code without threatening portability.
            The terms"Java Virtual Machine" and "JVM" mean a Virtual Machine for the Java platform.
            </p>
            <h3>What can Java technology do?</h3>
            <p>
            The general-purpose, high-level Java programming language is a powerful software platform. Every full implementation of the Java platform gives you the following features:
            Development Tools: The development tools provide everything you'll need for compiling, running, monitoring, debugging, and documenting your applications. As a new developer, the main tools you'll be using are the javac compiler, the java launcher, and the javadoc documentation tool.
            Application Programming Interface (API): The API provides the core functionality of the Java programming language. It offers a wide array of useful classes ready for use in your own applications. It spans everything from basic objects, to networking and security, to XML generation and database access, and more. The core API is very large; to get an overview of what it contains, consult the Java Platform Standard Edition 8 Documentation.
            Deployment Technologies: The JDK software provides standard mechanisms such as the Java Web Start software and Java Plug-In software for deploying your applications to end users.
            User Interface Toolkits: The JavaFX, Swing, and Java 2D toolkits make it possible to create sophisticated Graphical User Interfaces (GUIs).
            Integration Libraries: Integration libraries such as the Java IDL API, JDBC API, Java Naming and Directory Interface (JNDI) API, Java RMI, and Java Remote Method Invocation over Internet Inter-ORB Protocol Technology (Java RMI-IIOP Technology) enable database access and manipulation of remote objects.
            </p>

    Creating Graphical User Interfaces

    A comprehensive introduction to GUI creation on the Java platform.
            
        
    Specialized Trails and Lessons

    Lessons for specialized and expert user.

        Custom networking

            <h3>What You May Already Know About Networking in Java</h3>
            <p>
            The word networking strikes fear in the hearts of many programmers. Fear not! Using the networking capabilities provided in the Java environment is quite easy. In fact, you may be using the network already without even realizing it!
            </p>
            <h4>Loading Applets from the Network</h4>
            <p>
            If you have access to a Java-enabled browser, you have undoubtedly already executed many applets. The applets you've run are referenced by a special tag in an HTML file — the <APPLET> tag. Applets can be located anywhere, whether on your local machine or somewhere out on the Internet. The location of the applet is completely invisible to you, the user. However, the location of the applet is encoded within the <APPLET> tag. The browser decodes this information, locates the applet, and runs it. If the applet is on some machine other than your own, the browser must download the applet before it can be run.
            This is the highest level of access that you have to the Internet from the Java development environment. Someone else has taken the time to write a browser that does all of the grunt work of connecting to the network and getting data from it, thereby enabling you to run applets from anywhere in the world.
            The Java Applets trail describes how to write Java applets from A to Z.
            <h4>Loading Images from URLs</h4>
            <p>
            If you've ventured into writing your own Java applets and applications, you may have run into a class in the java.net package called URL. This class represents a Uniform Resource Locator and is the address of some resource on the network. Your applets and applications can use a URL to reference and even connect to resources out on the network. For example, to load an image from the network, your Java program must first create a URL that contains the address to the image.
            This is the next highest level of interaction you can have with the Internet — your Java program gets an address of something it wants, creates a URL for it, and then uses some existing function in the Java development environment that does the grunt work of connecting to the network and retrieving the resource.
            </p>

        Generics

            <h3>Introduction</h3>
            <p>
            JDK 5.0 introduces several new extensions to the Java programming language. One of these is the introduction of generics.
            This trail is an introduction to generics. You may be familiar with similar constructs from other languages, most notably C++ templates. If so, you'll see that there are both similarities and important differences. If you are unfamiliar with look-a-alike constructs from elsewhere, all the better; you can start fresh, without having to unlearn any misconceptions.
            Generics allow you to abstract over types. The most common examples are container types, such as those in the Collections hierarchy.
            Here is a typical usage of that sort:
            </p>
            <p>

            List myIntList = new LinkedList(); // 1
            myIntList.add(new Integer(0)); // 2
            Integer x = (Integer) myIntList.iterator().next(); // 3
            </p>
            <p>      

            The cast on line 3 is slightly annoying. Typically, the programmer knows what kind of data has been placed into a particular list. However, the cast is essential. The compiler can only guarantee that an Object will be returned by the iterator. To ensure the assignment to a variable of type Integer is type safe, the cast is required.
            Of course, the cast not only introduces clutter. It also introduces the possibility of a run time error, since the programmer may be mistaken.
            What if programmers could actually express their intent, and mark a list as being restricted to contain a particular data type? This is the core idea behind generics. Here is a version of the program fragment given above using generics:
            </p>
            <p>

            List<Integer> 
                myIntList = new LinkedList<Integer>(); // 1'
            myIntList.add(new Integer(0)); // 2'
            Integer x = myIntList.iterator().next(); // 3'
            </p>
            <p>

            Notice the type declaration for the variable myIntList. It specifies that this is not just an arbitrary List, but a List of Integer, written List<Integer>. We say that List is a generic interface that takes a type parameter--in this case, Integer. We also specify a type parameter when creating the list object.
            Note, too, that the cast on line 3' is gone.
            Now, you might think that all we've accomplished is to move the clutter around. Instead of a cast to Integer on line 3, we have Integer as a type parameter on line 1'. However, there is a very big difference here. The compiler can now check the type correctness of the program at compile-time. When we say that myIntList is declared with type List<Integer>, this tells us something about the variable myIntList, which holds true wherever and whenever it is used, and the compiler will guarantee it. In contrast, the cast tells us something the programmer thinks is true at a single point in the code.
            The net effect, especially in large programs, is improved readability and robustness.
            </p>
            <h3>Defining Simple Generics</h3>
            <p>
            Here is a small excerpt from the definitions of the interfaces List and Iterator in package java.util:
            </p>
            <p>
            public interface List <E> {
                void add(E x);
                Iterator<E> iterator();
            }
            </p>
            <p>
            public interface Iterator<E> {
                E next();
                boolean hasNext();
            }
            </p>
            <p>
            This code should all be familiar, except for the stuff in angle brackets. Those are the declarations of the formal type parameters of the interfaces List and Iterator.
            Type parameters can be used throughout the generic declaration, pretty much where you would use ordinary types (though there are some important restrictions; see the section The Fine Print.
            In the introduction, we saw invocations of the generic type declaration List, such as List<Integer>. In the invocation (usually called a parameterized type), all occurrences of the formal type parameter (E in this case) are replaced by the actual type argument (in this case, Integer).
            You might imagine that List<Integer> stands for a version of List where E has been uniformly replaced by Integer:
            </p>
            <p>
            public interface IntegerList {
                void add(Integer x);
                Iterator<Integer> iterator();
            }
            </p>
            <p>
            This intuition can be helpful, but it's also misleading.
            It is helpful, because the parameterized type List<Integer> does indeed have methods that look just like this expansion.
            It is misleading, because the declaration of a generic is never actually expanded in this way. There aren't multiple copies of the code--not in source, not in binary, not on disk and not in memory. If you are a C++ programmer, you'll understand that this is very different than a C++ template.
            A generic type declaration is compiled once and for all, and turned into a single class file, just like an ordinary class or interface declaration.
            Type parameters are analogous to the ordinary parameters used in methods or constructors. Much like a method has formal value parameters that describe the kinds of values it operates on, a generic declaration has formal type parameters. When a method is invoked, actual arguments are substituted for the formal parameters, and the method body is evaluated. When a generic declaration is invoked, the actual type arguments are substituted for the formal type parameters.
            A note on naming conventions. We recommend that you use pithy (single character if possible) yet evocative names for formal type parameters. It's best to avoid lower case characters in those names, making it easy to distinguish formal type parameters from ordinary classes and interfaces. Many container types use E, for element, as in the examples above. We'll see some additional conventions in later examples.
            </p>

Computer network

(Descrizione)A computer network is a digital telecommunications network which allows nodes to share resources.
In computer networks, computing devices exchange data with each other using connections (data links) between nodes.
These data links are established over cable media such as wires or optic cables, or wireless media such as Wi-Fi. 


